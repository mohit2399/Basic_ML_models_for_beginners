{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175073d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import numpy\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251acb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset is taken from https://archive.ics.uci.edu/ml/datasets/sms+spam+collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a6e3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load the dataset\n",
    "df= pd.read_table('SMSSpamCollection', header=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dfded6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of          0                                                  1\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...    ...                                                ...\n",
      "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568   ham               Will ü b going to esplanade fr home?\n",
      "5569   ham  Pity, * was in mood for that. So...any other s...\n",
      "5570   ham  The guy did some bitching but I acted like i'd...\n",
      "5571   ham                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.info) # or print(df.describe) for this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f62b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check class distribution\n",
    "\n",
    "classes= df[0]\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53072fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     ham\n",
      "1     ham\n",
      "2    spam\n",
      "3     ham\n",
      "4     ham\n",
      "5    spam\n",
      "6     ham\n",
      "7     ham\n",
      "8    spam\n",
      "9    spam\n",
      "Name: 0, dtype: object\n",
      "[0 0 1 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "# convert ham and spam to 0 and 1 respectively\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder= LabelEncoder()\n",
    "Y= encoder.fit_transform(classes)\n",
    "print(classes[:10])\n",
    "print(Y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd6701cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Go until jurong point, crazy.. Available only ...\n",
      "1                        Ok lar... Joking wif u oni...\n",
      "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    U dun say so early hor... U c already then say...\n",
      "4    Nah I don't think he goes to usf, he lives aro...\n",
      "5    FreeMsg Hey there darling it's been 3 week's n...\n",
      "6    Even my brother is not like to speak with me. ...\n",
      "7    As per your request 'Melle Melle (Oru Minnamin...\n",
      "8    WINNER!! As a valued network customer you have...\n",
      "9    Had your mobile 11 months or more? U R entitle...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# store the SMS message data\n",
    "text_messages= df[1]\n",
    "print(text_messages[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8f55fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-dcd77b526d8f>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed= text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$', 'emailaddr')\n",
      "<ipython-input-15-dcd77b526d8f>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed= processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','webaddress')\n",
      "<ipython-input-15-dcd77b526d8f>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed= processed.str.replace(r'£|\\$', 'moneysymb')\n",
      "<ipython-input-15-dcd77b526d8f>:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed= processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','phonenumbr')\n",
      "<ipython-input-15-dcd77b526d8f>:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed= processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
      "<ipython-input-15-dcd77b526d8f>:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed= processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
      "<ipython-input-15-dcd77b526d8f>:23: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed= processed.str.replace(r'\\s+', ' ')\n",
      "<ipython-input-15-dcd77b526d8f>:26: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  processed= processed.str.replace(r'^\\s+|\\s+?$', '')\n"
     ]
    }
   ],
   "source": [
    "# to create expression for email and other things, we can use regular expression website \n",
    "# with those expressions we will replace email, mob nos, urls, symbols, etc\n",
    "\n",
    "# replacing emails with 'emailaddr'\n",
    "processed= text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$', 'emailaddr')\n",
    "\n",
    "# replace urls with 'webaddress'\n",
    "processed= processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','webaddress')\n",
    "\n",
    "# replace money symbols with 'moneysymb'\n",
    "processed= processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "\n",
    "# replace 10 digit phone numbers with 'phonenumber'\n",
    "processed= processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','phonenumbr')\n",
    "\n",
    "# replace normal numbers with 'numbr'\n",
    "processed= processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "\n",
    "# remove punctuation\n",
    "processed= processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# replace whitespace between terms with single space\n",
    "processed= processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# replace leading and trailing whitespace\n",
    "processed= processed.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31265c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the words to lower case so that HELLO, Hello, hello, are all same thing.\n",
    "processed= processed.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d50b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from messages\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "processed= processed.apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c2f4c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove word stems using porter stemmer\n",
    "ps= nltk.PorterStemmer()\n",
    "\n",
    "processed= processed.apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d5c9393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go jurong point crazi avail bugi n great world...\n",
      "1                                   ok lar joke wif u oni\n",
      "2       free entri numbr wkli comp win fa cup final tk...\n",
      "3                     u dun say earli hor u c alreadi say\n",
      "4                    nah think goe usf live around though\n",
      "                              ...                        \n",
      "5567    numbrnd time tri numbr contact u u moneysymbnu...\n",
      "5568                              ü b go esplanad fr home\n",
      "5569                                    piti mood suggest\n",
      "5570    guy bitch act like interest buy someth el next...\n",
      "5571                                       rofl true name\n",
      "Name: 1, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "01ec9f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 6530\n",
      "most common: [('numbr', 2648), ('u', 1207), ('call', 674), ('go', 456), ('get', 451), ('ur', 391), ('gt', 318), ('lt', 316), ('come', 304), ('moneysymbnumbr', 303), ('ok', 293), ('free', 284), ('day', 276), ('know', 275), ('love', 266)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# creating a bag-of-words\n",
    "all_words= []\n",
    "\n",
    "for message in processed:\n",
    "    words= word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words= nltk.FreqDist(all_words)\n",
    "\n",
    "# print total no of words and 15 most common words\n",
    "print('total words: {}'.format(len(all_words)))\n",
    "print('most common: {}'.format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "31de3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of words used as features\n",
    "word_features= list(all_words.keys())[:] # add no of top common words you want to use as features. i am using all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3dc32df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "jurong\n",
      "point\n",
      "crazi\n",
      "avail\n",
      "bugi\n",
      "n\n",
      "great\n",
      "world\n",
      "la\n",
      "e\n",
      "buffet\n",
      "cine\n",
      "got\n",
      "amor\n",
      "wat\n"
     ]
    }
   ],
   "source": [
    "# define a find features function\n",
    "def find_features(message):\n",
    "    words= word_tokenize(message)\n",
    "    features={}\n",
    "    for word in word_features:\n",
    "        features[word]=(word in words)\n",
    "        \n",
    "    return features\n",
    "\n",
    "# lets see an example\n",
    "features=find_features(processed[0])\n",
    "for key, value in features.items():\n",
    "    if value==True:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b5be3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do it for all the messages\n",
    "messages = list(zip(processed, Y))\n",
    "\n",
    "# define a seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(messages)\n",
    "\n",
    "# call find_features function for each SMS message\n",
    "featuresets = [(find_features(text), label) for (text, label) in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba1460ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 4179\n",
      "testing: 1393\n"
     ]
    }
   ],
   "source": [
    "# split training and testing data sets using sklearn\n",
    "from sklearn import model_selection\n",
    "\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size=0.25, random_state=seed)\n",
    "\n",
    "print('training: {}'.format(len(training)))\n",
    "print('testing: {}'.format(len(testing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0e19e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b2112bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining models to train\n",
    "\n",
    "names=['K Nearest Neighbours', 'Decision Tree', 'Random Forect', 'Logistic Regression', \n",
    "       'SGD Classifier', 'Naive Bayes', 'SVM Linear']\n",
    "classifier=[KNeighborsClassifier(), DecisionTreeClassifier(), RandomForestClassifier(),\n",
    "           LogisticRegression(), SGDClassifier(max_iter=100), MultinomialNB(),\n",
    "           SVC(kernel='linear')]\n",
    "\n",
    "models=zip(names, classifier)\n",
    "#print(list(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7a69d287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbours : Accuracy : 92.89303661162958\n",
      "Decision Tree : Accuracy : 97.34386216798278\n",
      "Random Forect : Accuracy : 97.70279971284997\n",
      "Logistic Regression : Accuracy : 97.5592246949031\n",
      "SGD Classifier : Accuracy : 97.70279971284997\n",
      "Naive Bayes : Accuracy : 97.91816223977028\n",
      "SVM Linear : Accuracy : 97.70279971284997\n"
     ]
    }
   ],
   "source": [
    "# wrap models in NLTK\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy=nltk.classify.accuracy(nltk_model, testing)* 100\n",
    "    print('{} : Accuracy : {}'.format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "10e2f9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Method Accuracy: 97.5592246949031\n"
     ]
    }
   ],
   "source": [
    "# ensemble method - Voting Classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# defining models to train\n",
    "\n",
    "names=['K Nearest Neighbours', 'Decision Tree', 'Random Forect', 'Logistic Regression', \n",
    "       'SGD Classifier', 'Naive Bayes', 'SVM Linear']\n",
    "classifier=[KNeighborsClassifier(), DecisionTreeClassifier(), RandomForestClassifier(),\n",
    "           LogisticRegression(), SGDClassifier(max_iter=100), MultinomialNB(),\n",
    "           SVC(kernel='linear')]\n",
    "\n",
    "models=list(zip(names, classifier))\n",
    "\n",
    "nltk_ensemble= SklearnClassifier(VotingClassifier(estimators= models, voting= 'hard', n_jobs=-1))\n",
    "nltk_ensemble.train(training)\n",
    "accuracy= nltk.classify.accuracy(nltk_ensemble, testing) * 100\n",
    "print('Ensemble Method Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "939aeefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class label prediction for testing set\n",
    "txt_features, labels = zip(*testing)\n",
    "prediction= nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "56991778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1212\n",
      "           1       0.99      0.82      0.90       181\n",
      "\n",
      "    accuracy                           0.98      1393\n",
      "   macro avg       0.98      0.91      0.94      1393\n",
      "weighted avg       0.98      0.98      0.97      1393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>ham</th>\n",
       "      <td>1210</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>32</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted     \n",
       "                  ham spam\n",
       "actual ham       1210    2\n",
       "       spam        32  149"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a confusion matrix and classification report\n",
    "print(classification_report(labels, prediction))\n",
    "\n",
    "pd.DataFrame(\n",
    "confusion_matrix(labels, prediction),\n",
    "index=[['actual', 'actual'], ['ham', 'spam']],\n",
    "columns=[['predicted', 'predicted'], ['ham', 'spam']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ebd06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
